{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install `transformers` from master\n",
    "%pip install git+https://github.com/huggingface/transformers\n",
    "%pip list | grep -E 'transformers|tokenizers'\n",
    "# transformers version at notebook update --- 2.11.0\n",
    "# tokenizers version at notebook update --- 0.8.0rc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers.implementations import ByteLevelBPETokenizer\n",
    "from tokenizers.processors import BertProcessing\n",
    "\n",
    "\n",
    "tokenizer = ByteLevelBPETokenizer(\n",
    "    \"BPEtokenizer/vocab.json\",\n",
    "    \"BPEtokenizer/merges.txt\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer._tokenizer.post_processor = BertProcessing(\n",
    "    (\"</s>\", tokenizer.token_to_id(\"</s>\")),\n",
    "    (\"<s>\", tokenizer.token_to_id(\"<s>\")),\n",
    ")\n",
    "tokenizer.enable_truncation(max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaConfig\n",
    "\n",
    "config = RobertaConfig(\n",
    "    vocab_size=50_000,\n",
    "    max_position_embeddings=514,\n",
    "    num_attention_heads=12,\n",
    "    num_hidden_layers=6,\n",
    "    type_vocab_size=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaTokenizerFast\n",
    "\n",
    "tokenizer = RobertaTokenizerFast.from_pretrained(\"BPEtokenizer\", max_len=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaForMaskedLM\n",
    "\n",
    "model = RobertaForMaskedLM(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81966416"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.num_parameters()\n",
    "# => 84 million parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset text (C:/Users/Jonathan Ipe/.cache/huggingface/datasets/text/default-9260811a8c434195/0.0.0/cb1e9bd71a82ad27976be3b12b407850fe2837d80c22c5e03a28949843a8ace2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text'],\n",
       "    num_rows: 28046\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"text\", data_files=\"unlabeled_data_sentences.txt\", split='train') #, split='train', streaming=True)\n",
    "# dataset = load_dataset(\"text\", data_files=r\"..\\ttmp\\unlabeled_data_sentences.txt\", split='train').shuffle()\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.train_test_split(test_size=0.2)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = dataset['train']\n",
    "val_dataset = dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f892cae734324931b4cfd0ad31a0b8b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/28046 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], truncation=True, padding='max_length', max_length=512)\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset\n",
    "train_dataset_size = 1000  # Specify the number of training data points\n",
    "val_dataset_size = 250    # Specify the number of validation data points\n",
    "\n",
    "train_dataset = tokenized_datasets.take(train_dataset_size)\n",
    "val_dataset = tokenized_datasets.skip(train_dataset_size).take(val_dataset_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# from transformers import LineByLineTextDataset\n",
    "\n",
    "# dataset = LineByLineTextDataset(\n",
    "#     tokenizer=tokenizer,\n",
    "#     file_path=\"unlabeled_data_sentences.txt\",\n",
    "#     block_size=128,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForLanguageModeling\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer, mlm=True, mlm_probability=0.15\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "    return {\"accuracy\": accuracy}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import wandb\n",
    "os.environ[\"WANDB_PROJECT\"]=\"my-awesome-project\"\n",
    "os.environ[\"WANDB_LOG_MODEL\"]=\"true\"\n",
    "os.environ[\"WANDB_WATCH\"]=\"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"BERT-Pretrained\",\n",
    "    # report_to=\"wandb\",\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=8,\n",
    "    save_steps=500,\n",
    "    # save_total_limit=2,\n",
    "    max_steps=100,  # specify the number of steps\n",
    "    # logging_dir='./logs',  # directory for storing logs\n",
    "    logging_steps=10,  # log training information every 50 steps\n",
    "    # evaluation_strategy=\"steps\",  # evaluate every `logging_steps` steps\n",
    "    # load_best_model_at_end=True,  # load the best model at the end of training\n",
    "    metric_for_best_model='loss',  # use accuracy to find the best model\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=tokenized_datasets,\n",
    "    # eval_dataset=val_dataset,  # If you have a validation dataset\n",
    "    # compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0062e540bb54e918c1f837bce2584c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 7.1612, 'learning_rate': 4.5e-05, 'epoch': 0.0}\n",
      "{'loss': 6.7803, 'learning_rate': 4e-05, 'epoch': 0.01}\n",
      "{'loss': 6.1896, 'learning_rate': 3.5e-05, 'epoch': 0.01}\n",
      "{'loss': 5.878, 'learning_rate': 3e-05, 'epoch': 0.01}\n",
      "{'loss': 5.4853, 'learning_rate': 2.5e-05, 'epoch': 0.01}\n",
      "{'loss': 5.2184, 'learning_rate': 2e-05, 'epoch': 0.02}\n",
      "{'loss': 5.0677, 'learning_rate': 1.5e-05, 'epoch': 0.02}\n",
      "{'loss': 4.9044, 'learning_rate': 1e-05, 'epoch': 0.02}\n",
      "{'loss': 4.8558, 'learning_rate': 5e-06, 'epoch': 0.03}\n",
      "{'loss': 4.851, 'learning_rate': 0.0, 'epoch': 0.03}\n",
      "{'train_runtime': 186.1136, 'train_samples_per_second': 4.298, 'train_steps_per_second': 0.537, 'train_loss': 5.639166145324707, 'epoch': 0.03}\n",
      "CPU times: total: 3min 6s\n",
      "Wall time: 3min 6s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=100, training_loss=5.639166145324707, metrics={'train_runtime': 186.1136, 'train_samples_per_second': 4.298, 'train_steps_per_second': 0.537, 'train_loss': 5.639166145324707, 'epoch': 0.03})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'wandb' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Jonathan Ipe\\Dropbox\\Coding\\E208-Final-Project\\pretraining-bert-unlabeled.ipynb Cell 21\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Jonathan%20Ipe/Dropbox/Coding/E208-Final-Project/pretraining-bert-unlabeled.ipynb#X35sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m wandb\u001b[39m.\u001b[39mfinish()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'wandb' is not defined"
     ]
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(\"BERT-Pretrained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': '¯¯·¯±¯¯¯ ¯¯¯¯ï¯¯¯ ¯į¯¯¯¯¯¯ ¯¯¯¯į¯¯¯ ¯¯¯¯ï¯¯¯ ¯¯±¯į¯¯¯ ¯¯¯¯¿¯¯¯ ¯¯³¯Ï¯¯¯ ¯¯¯¯¿¯¯¯ ¯¯±¯į¯¯¯ ¯¯¯¯¿¯¯¯ ¯¯°¯¿¯¯¯ ¯¯¯¯·¯¯¯ ¯ï¯¯¯°¯¯ ¯¯¯¯·¯¯¯ ¯į¯¯·¯¯¯ ¯¯¯¯³¯¯¯ ¯¯¯¯±¯¯¯ ¯Ï¯¯³¯¯¯ ¯¯¯¯·¯¯¯ ¯¯¯¯¿¯¯¯ ¯¯¯¯·¯¯¯ ¯¿¯¯¿¯¯¯ ¯¯·¯¯¯¯¯ ¯¯³¯¯¯¯¯ ¯¯·¯¯¯¯¯ ¯¯¯¯ï¯¯¯ ¯¯°¯Ï¯¯¯ ¯¯¯¯ï¯¯¯ ¯¯±¯į¯¯¯ ¯¯¯¯¯°¯¯ ¯¯°¯į¯¯¯ ¯¯¯¯Ï¯¯¯ ¯¯·¯ï¯¯¯ ¯¯¯¯į¯¯¯ ¯¯°¯ï¯¯¯ ¯¯¯¯¿¯¯¯ ¯¯·¯±¯¯¯ ¯¯°¯Ï¯¯¯ ¯¯¯¯ï¯¯¯ ¯į¯¯Ï¯¯¯ ¯¯¯¯¿¯¯¯ ¯¯¿¯·¯¯¯ ¯¯¯¯Ï¯¯¯ ¯į¯¯¿¯¯¯ ¯¯¯¯·¯¯¯ ¯į¯¯¯°¯¯ ¯ï¯¯¿¯¯¯ ¯Ï¯¯·¯¯¯ ¯ï¯¯¿¯¯¯ ¯¯¯¯ï¯¯¯ ¯į¯¯Ï¯¯¯ ¯¯¯¯į¯¯¯ ¯¯°¯ï¯¯¯ ¯¯¯¯į¯¯¯ ¯į¯¯¯°¯¯ ¯¯¯¯¯±¯¯ ¯¯°¯Ï¯¯¯ ¯°¯¯¯¯¯¯ ¯¯¯¯¿±¯¯ ¯¿¯¯¿¯¯¯ ¯¯¯¯¯·¯¯ ¯Ï³¯¯³¯¯ ¯ï¯¯¯·¯¯ ¯į¯¯¯¯¯¯ ¯Ï¯¯¯°¯¯ ¯ï¯¯¯¯¯¯ ¯į¯¯¯±¯¯ ¯¯°¯¯¯¯¯ ¯į¯¯¯°¯¯ ¯Ï¯¯¯¯¯¯ ¯ï¯¯¯·¯¯ ¯į¯¯¯¯¯¯ ¯ï¯¯¯°¯¯ ¯¿¯¯¯¯¯¯ ¯Ï¯¯¯°¯¯ ¯ï¯¯¯¯¯¯ ¯Ï¯¯į¯¯¯ ¯¿¯¯¯¯¯¯ ¯·¯¯¯¿¯¯ ¯Ï¯¯¯¯¯¯ ¯¿¯¯į¯¯¯ ¯·¯¯¯¯¯¯ ¯¯·¯±¯¯¯ ¯¿¯¯į¯¯¯ ¯¯·¯ï¯¯¯ ¯¯³¯Ï¯¯¯ ¯¯·¯ï¯¯¯ ¯¯¯¯į¯¯¯ ¯¯°¯ï¯¯¯ ¯¯¯¯·¯¯¯ ¯¯±¯¿¯¯¯ ¯¯¯°¯·¯¯ ¯¯į¯¯³¯¯ ¯¯¯°¯·¯¯ ¯¯¯±¯¯¯¯ ¯¯¯°¯°¯¯ ¯¯Ï¯¯¯¯¯ ¯¯ï¯¯±¯¯ ¯¯¯¯¯³¯¯ ¯¯Ï¯¯±¯¯ ¯¯¯¯į¯¯¯ ¯¯¿¯¯³¯¯ ¯¯¯¯į¯¯¯ ¯¯·¯¯·¯¯ ¯¯¯¯į¯¯¯ ¯¯³¯¯¿¯¯ ¯¯¯¯¯Ï¯¯ ¯·¯¯¯¿¯¯ ¯¯¯¯¯³¯¯ ¯¿¯¯¯Ï¯¯ ¯¯¯¯¯³¯¯ ¯Ï¯¯¯Ï¯¯ ¯¯¯¯¯±¯¯ ¯ï¯¯¯°¯¯ ¯¯¯¯¯±¯¯ ¯¯¿¯¯°¯¯ ¯¯¯¯ï¯¯¯ ¯¯·¯¯±¯¯ ¯¯¯¯ï¯¯¯ ¯¯³¯¯³¯¯ ¯¯¯¯ï¯¯¯ ¯¯±¯¯·¯¯ ¯¯¯¯¯¿¯¯ ¯¯¯¯¯·¯¯ ¯¯¯¯¯±¯¯ ¯·¯¯¯¿¯¯ ¯¯¯¯¯±¯¯ ¯¿¯¯¯Ï¯¯ ¯¯¯¯¯±¯¯ ¯¯÷¯¯¯¯¯ ¯¯·¯ı¯¯¯ ¯¯¯¯¯±¯¯ ¯Ï¯¯¯ï¯¯ ¯¯¯¯¯į¯¯ ¯¯¿¯¯ï¯¯ ¯¯¯¯¯³¯¯ ¯¯·¯¯Ï¯¯ ¯¯¯¯¯ï¯¯ ¯¯ï¯¯Ï¯¯ ¯¯¯¯¯±¯¯ ¯¯³¯¯¿¯¯ ¯¯¯¯¯Ï¯¯ ¯¯Ï¯¯¿¯¯ ¯¯¯¯¯°¯¯ ¯¯±¯¯·¯¯ ¯¯¯¯¯¿¯¯ ¯¯¯°¯·¯¯ ¯¯¯¯¯±¯¯ ¯¯¯°¯³¯¯ ¯¯¯±¯¯¯¯ ¯¯¯°Ï¯¯¯ ¯¯ï¯¿¯¯¯ ¯¯į¯Ï¯¯¯ ¯¯¯°¯¯¯¯ ¯¯į¯¯³¯¯ ¯¯Ï¯¯¯¯¯ ¯¯¯°¿¯¯¯ ¯¯į¯¯¯¯¯ ¯¯ï¯¯±¯¯ ¯¯Ï¯¯¯¯¯ ¯¯¿¯·¯¯¯ ¯¯·¯¯¯¯¯ ¯¯¿¯¯°¯¯ ¯¯Ï¯¯¯¯¯ ¯¯±¯¯±¯¯ ¯¯¯°¯¯¯¯ ¯¯į¯¯¯¯¯ ¯¯¯°¯¯¯¯ ¯¯¯¯¿¯¯¯ ¯¯Ï¯·¯¯¯ ¯¯¯¯¿¯¯¯ ¯¯ï¯Ï¯¯¯ ¯¯¯¯ï¯¯¯ ¯¯Ï¯Ï¯¯¯ ¯¯¯¯·¯¯¯ ¯¯¯°¿¯¯¯ ¯¯¯¯Ï¯¯¯ ¯¯Ï¯¿¯¯¯ ¯¯¯¯³¯¯¯ ¯¯·¯±¯¯¯ ¯¯Ï¯·¯¯¯ ¯¯¯¯¿¯¯¯ ¯¯¿¯·¯¯¯ ¯¯¯¯³¯¯¯ ¯¯¯±±¯¯¯ ¯¯¯¯·¯¯¯ ¯¯¿¯³¯¯¯ ¯¯¯¯±¯¯¯ ¯¯¿¯³¯¯¯ ¯¯·¯ï¯¯¯ ¯¯³¯¯¯¯¯ ¯¯·¯¯±¯¯ ¯¯¿¯¯°¯¯ ¯¯Ï¯į¯¯¯ ¯¯¿¯¯±¯¯ ¯¯Ï¯¯°¯¯ ¯¯¯¯į¯¯¯ ¯¯³¯ï¯¯¯ ¯¯¯¯Ï¯¯¯ ¯¯±¯ï¯¯¯ ¯¯°¯¯¯¯¯ ¯į¯¯·¯¯¯ ¯ï¯¯¯¯¯¯ ¯¯±¯¿¯¯¯ ¯¯³¯¯¯¯¯ ¯¯±¯·¯¯¯ ¯į¯¯¯¯¯¯ ¯¯°¯ï¯¯¯ ¯¯±¯¯¯¯¯ ¯¯°¯·¯¯¯ ¯ï¯¯¯¯¯¯ ¯į¯¯·¯¯¯ ¯¯°¯¯¯¯¯ ¯į¯¯³¯¯¯ ¯ï¯¯¯¯¯¯ ¯Ï¯¯į¯¯¯ ¯į¯¯¯¯¯¯ ¯ï¯¯³¯¯¯ ¯Ï¯¯¯¯¯¯ ¯ï¯¯³¯¯¯ ¯¯Ï¯±¯¯¯ ¯¯¯¯°¯¯¯ ¯¯¿¯±¯¯¯ ¯¯¯¯³¯¯¯ ¯¯·¯·¯¯¯ ¯¯¯¯³¯¯¯ ¯¯·¯±¯¯¯ ¯¯³¯ï¯¯¯ ¯¯¯¯¿¯¯¯ ¯¯¯±Ï¯¯¯ ¯¯¯¯ï¯¯¯ ¯¯¯°Ï¯¯¯ ¯¯¯¯ï¯¯¯ ¯¯į¯į¯¯¯ ¯¯¯¯ï¯¯¯ ¯¯ï¯¯³¯¯ ¯¯¯¯¯°¯¯ ¯į¯¯¯±¯¯ ¯¯¯¯¯³¯¯ ¯ï¯¯¯±¯¯ ¯¯¯¯¯³¯¯ ¯Ï¯¯¯·¯¯ ¯¯¯¯¯³¯¯ ¯¿¯¯¯ï¯¯ ¯¯¯¯¯¿¯¯ ¯¯·¯¯Ï¯¯ ¯¯¿¯į¯¯¯ ¯¯Ï¯¯°¯¯ ¯¯¯¯¯±¯¯ ¯¯ï¯¯³¯¯ ¯¯¯¯¯±¯¯ ¯¯³¯¯Ï¯¯ ¯¯¯¯¯·¯¯ ¯·¯¯¯¿¯¯ ¯¿¯¯ï¯¯¯ ¯Ï¯¯į¯¯¯ ¯¯¯¯¯°¯¯ ¯ï¯¯¯±¯¯ ¯¯¯¯¯°¯¯ ¯¯¯¯¯¿¯¯ ¯¯¯¯¯³¯¯ ¯¯ï¯¯·¯¯ ¯¯Ï¯¯°¯¯ ¯¯ï¯¯±¯¯ ¯¯¯¯¯³¯¯ ¯¯·¯¯·¯¯ ¯¯¯¯¯±¯¯ ¯¯¿¯¯³¯¯ ¯¯¯¯¯·¯¯ ¯¯·¯¯³¯¯ ¯¯¯¯¯°¯¯ ¯¯ï¯¯±¯¯ ¯¯¯¯¯³¯¯ ¯¯·¯¯±¯¯ ¯¯¯¯į¯¯¯ ¯¯·¯±¯¯¯ ¯¯·¯¯°¯¯ ¯¯¯¯¯±¯¯ ¯¯³¯¯°¯¯ ¯¯¯¯į¯¯¯ ¯¯į¯ï¯¯¯ ¯¯¯¯į¯¯¯ ¯¯³¯¯°¯¯ ¯¯¯¯ï¯¯¯ ¯¯³¯¿¯¯¯ ¯¯±¯į¯¯¯ ¯¯°¯ï¯¯¯ ¯¯±¯į¯¯¯ ¯į¯¯¯¯¯¯ ¯¯°¯¿¯¯¯ ¯¯±¯¯¯¯¯ ¯¯³¯Ï¯¯¯ ¯¯·¯¯¯¯¯ ¯¯³¯¿¯¯¯ ¯¯°¯¯¯¯¯ ¯¯±¯į¯¯¯ ¯¯³¯¯¯¯¯ ¯¯±¯¿¯¯¯ ¯į¯¯¯¯¯¯ ¯¯°¯¿¯¯¯ ¯¯±¯¯¯¯¯ ¯¯°¯·¯¯¯ ¯į¯¯¯¯¯¯ ¯ï¯¯¯°¯¯ ¯¯°¯¯¯¯¯ ¯į¯¯·¯¯¯ ¯ï¯¯¯¯¯¯ ¯į¯¯·¯¯¯ ¯¯ï¯³¯¯¯ ¯¯Ï¯±¯¯¯ ¯¯ï¯³¯¯¯ ¯¯¯¯¿¯¯¯ ¯¯¿¯·¯¯¯ ¯¯¯¯Ï¯¯¯ ¯¯±¯¿¯¯¯ ¯¯·¯¯¯¯¯ ¯¯³¯¯¯¯¯ ¯¯¿¯¯±¯¯ ¯¯·¯ï¯¯¯ ¯¿¯¯¯¯¯¯ ¯¯¯¯į¿¯¯'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(trainer.state.log_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot(x='epoch', y='train_loss')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
